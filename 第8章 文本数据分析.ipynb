{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eaea00-0d32-484d-b4d5-77acdeb3ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8.1 文本数据分析工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f2088-a2dd-4975-ac25-10a4da86d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0dec91-e61f-45f9-8b7b-d9d056608004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32a204-204c-48c5-9dc6-07d11cfc2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a68d0-2e9b-41ea-9d82-e09f560cd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "'brown中一共有{}个句子'.format(len(brown.sents()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6e89d-73a6-46a5-a339-d6b53867985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'brown中一共有{}个单词'.format(len(brown.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb272843-04fc-4c06-921e-62ca06307840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8.2 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43692d1-2f37-490b-a0b9-27133f60508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Python is a structured and powerful object-oriented programming language.'\n",
    "words = nltk.word_tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a508f4-75e4-4628-af4b-a2746983016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "sentence = '传智专修学院推出颠覆式办学模式'\n",
    "terms_list = jieba.cut(sentence, cut_all = True)\n",
    "print('【全模式】: '+'/'.join(terms_list))\n",
    "terms_list = jieba.cut(sentence, cut_all = False)\n",
    "print('【精确模式】: '+'/'.join(terms_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2924c3b-d35d-4fb2-bb4f-50677b5b34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = nltk.word_tokenize('Python is a structured and powerful object-oriented programming language.')\n",
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46265d6c-67f9-4963-a389-26e2a00ff3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stem = PorterStemmer()\n",
    "porter_stem.stem('watched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59da27-c83b-4f99-ad10-c859e875392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stem.stem('watching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0816af-904a-4db5-b553-9ffa3451cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stem = LancasterStemmer()\n",
    "lancaster_stem.stem('jumped')\n",
    "lancaster_stem.stem('jumping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3b7a8-d4aa-48af-afcf-f11456238ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import SnowballStemmer\n",
    "snowball_stem = SnowballStemmer('english')\n",
    "snowball_stem.stem('jumped')\n",
    "snowball_stem.stem('jumping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18693453-c55d-4986-b680-ac48a1f9462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import WordNetLemmatizer\n",
    "wordnet_lem = WordNetLemmatizer()\n",
    "wordnet_lem.lemmatize('book')\n",
    "wordnet_lem.lemmatize('went')\n",
    "wordnet_lem.lemmatize('did')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7f5b3-ca06-416f-85d6-84a2c815f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lem.lemmatize('went', pos = 'v')\n",
    "wordnet_lem.lemmatize('did', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbae5ec-c6d0-4d60-be7f-d2095a88e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sentence = 'Python is a structured and powerful object-oriented programming language.'\n",
    "words = nltk.word_tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45c882-7d58-4e82-9b0a-a0add0a0247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "remian_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c32e6c-68c3-4319-8a26-3cc98023f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        remain_words.append(word)\n",
    "remain_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967d551-bd01-47ce-aeb0-e0f37b934968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8.3 文本情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6d803-9da0-41f3-885c-87546ddb83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_one = 'This is a wonderful book'\n",
    "text_two = 'I like reading this book very much.'\n",
    "text_thr = 'This book reads well'\n",
    "text_fou = 'This book is not good'\n",
    "text_fiv = 'This is a very bad book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755d6d1-ad1b-413d-84ce-9d313a9de57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "def pret_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    wordnet_lematizer = WordNetLemmatizer()\n",
    "    words = [wordnet_lematizer.lemmatize(word) for word in words]\n",
    "    remain_words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return {word: True for word in remain_words}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a28a3d-f679-4a31-81a3-c69bfc13483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[pret_text(text_one), 1],\n",
    "              [pret_text(text_two), 1],\n",
    "              [pret_text(text_thr), 1],\n",
    "              [pret_text(text_fou), -1],\n",
    "              [pret_text(text_fiv), -1]\n",
    "demo_model = NaiveBayesClassifier.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554be24-1f78-41d5-994a-3a33cb103209",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text1 = 'I like this movie very much'\n",
    "demo_model.classify(pret_text(test_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96382f72-a374-49bc-b51a-35c10d2d1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text2 = 'The film is very much'\n",
    "demo_model.classify(pret_text(test_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e96bb6-1a62-4219-9ec5-2d2d1b487e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text3 = 'The film is terrible'\n",
    "demo_model.classify(pret_text(test_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fff7f-413a-4b82-9702-5601e3fe9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8.4 文本相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9106f6-13a4-4008-b971-88a50df3c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk import FreqDist\n",
    "text1 = 'John likes to watch movies'\n",
    "text2 = 'John also likes to watch football games'\n",
    "all_text = text1 + \" \" + text2\n",
    "words = nltk.word_tokenize(all_text)\n",
    "freq_dist = FreqDist(words)\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d808960-fea5-4dff-8d5f-b0e8fd35b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist['John']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74630bf2-5211-442d-bdf3-71192067a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "most_common_words = freq_dist.most_common(n)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201df7d8-fad0-4613-adde-6f78b66a30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_position(common_words):\n",
    "    result = {}\n",
    "    pos = 0\n",
    "    for word in common_words:\n",
    "        result[word[0]] = pos\n",
    "        pos += 1\n",
    "    return result\n",
    "pos_dict = find_position(most_common_words)\n",
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83a533-6561-472a-a884-7997ebfa7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(words):\n",
    "    freq_vec = [0] * n\n",
    "    for word in words:\n",
    "        if word in list(pos_dict.keys()):\n",
    "            freq_vec[pos_dict[word]] += 1\n",
    "        return freq_vec       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533d713-2b27-405f-8c55-8dc62308700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = text_to_vector(nltk.word_tokenize(text1))\n",
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8051b3f-cea1-4857-9e25-0ed72579d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector2 = text_to_vector(nltk.word_tokenize(text2))\n",
    "vector2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade04d9b-b283-49a6-8b1a-5269919b830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster.util import cosine_distance\n",
    "1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305dbb0-2222-42d6-97e4-d635dd1030f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8.5 文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316ecd1-04b4-4bc8-8805-d7db73cabe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "names = [(name, 'male') for name in names.words('male.txt')] \\ \n",
    "        + [(name, 'female') for name in names.words('female.txt')]\n",
    "random.shuffle(names)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7988dd6-2ae3-4c7a-a2e9-fefa2aa53f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'最后一个字母': word[-1], '倒数第二个字母': word[-2]}\n",
    "features = [(gender_features(n), g) for (n, g) in names]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30321b39-94d2-4cda-b12e-56812b71e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = features[500:], features[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f5177-2531-480d-9c7d-a20d566649fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0414fe5-3173-4319-a44a-a81a3d5cc6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classify({'last_letter': 'Ella'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e75194-bf18-46d7-801f-506c1b93fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18620cbc-ada3-44dd-8e57-e87ef24ee727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "from nltk.text import TextCollection\n",
    "corpus = TextCollection(['this is sentence one', \n",
    "                         'this is sentence two',\n",
    "                         'this is sentence three'])\n",
    "corpus.tf_idf('this', 'this is sentence four')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
